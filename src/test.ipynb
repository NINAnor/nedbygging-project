{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "\n",
    "import hydra\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from dataset.monthlysampler import loader\n",
    "from dataset.augmentations import build_transform\n",
    "\n",
    "ROOT_PATH = \"/data/Prosjekter3/154012_monitoring_natural_habitat_loss_in_norway_with_cop/R/DATA/For_MSc/Project_1/\"\n",
    "\n",
    "\n",
    "root = Path(ROOT_PATH)\n",
    "SIZE=256\n",
    "LENGTH=30\n",
    "BATCH_SIZE_FOR_STAT=16\n",
    "BATCH_SIZE_FOR_TRAINING=8\n",
    "\n",
    "train_path_imgs = root/'tra_scene'\n",
    "train_path_masks = root/'tra_truth'\n",
    "val_path_imgs = root/'val_scene'\n",
    "val_path_masks = root/'val_truth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class GeoSampler with abstract method __iter__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compute band mins and band maxes for image normalisation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m stat_train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtrain_path_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mSIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mLENGTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mBATCH_SIZE_FOR_STAT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mfor_stat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# instantiate the transform\u001b[39;00m\n\u001b[1;32m     12\u001b[0m train_transform \u001b[38;5;241m=\u001b[39m build_transform(stat_train_loader, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Code/nedbygging-project/src/dataset/monthlysampler.py:90\u001b[0m, in \u001b[0;36mloader\u001b[0;34m(path_imgs, path_masks, size, length, batch_size, transform, for_stat)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Choose the appropriate collate function\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m for_stat:\n\u001b[0;32m---> 90\u001b[0m     sampler \u001b[38;5;241m=\u001b[39m \u001b[43mGeoSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     collate_fn \u001b[38;5;241m=\u001b[39m stack_samples  \u001b[38;5;66;03m# No transformations needed for stats computation\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class GeoSampler with abstract method __iter__"
     ]
    }
   ],
   "source": [
    "# Compute band mins and band maxes for image normalisation\n",
    "stat_train_loader = loader(train_path_imgs, \n",
    "                            train_path_masks, \n",
    "                            SIZE, \n",
    "                            LENGTH, \n",
    "                            BATCH_SIZE_FOR_STAT, \n",
    "                            transform=None,\n",
    "                            for_stat=True)\n",
    "\n",
    "\n",
    "# instantiate the transform\n",
    "train_transform = build_transform(stat_train_loader, mode='train')\n",
    "val_transform = build_transform(stat_train_loader, mode='val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(stat_train_loader))['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([2.6552e+08, 1.3891e+08, 2.3694e+08, 1.9537e+08, 2.8000e+08, 1.5849e+08])\n"
     ]
    }
   ],
   "source": [
    "from dataset.augmentations import compute_band_minmax\n",
    "min, max = compute_band_minmax(stat_train_loader)\n",
    "\n",
    "print(min)\n",
    "print(max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose([\n",
       "  HorizontalFlip(p=0.5),\n",
       "  VerticalFlip(p=0.5),\n",
       "  RandomRotate90(p=0.5),\n",
       "  OneOf([\n",
       "    RandomBrightnessContrast(p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True, ensure_safe_range=False),\n",
       "    GaussNoise(p=0.5, std_range=(0.2, 0.44), mean_range=(0.0, 0.0), per_channel=True, noise_scale_factor=1.0),\n",
       "    ColorJitter(p=0.5, brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.5, 0.5)),\n",
       "  ], p=0.8),\n",
       "  Normalize(p=1.0, mean=[6890000.0, 5150000.0, 3020000.0, 2910000.0, 1850000.0, 335000.0, 7300000.0, 4770000.0, 2585000.0, 2310000.0, 1560000.0, 315000.0, 7790000.0, 5460000.0, 3040000.0, 2720000.0, 2170000.0, 490000.0, 8900000.0, 6250000.0, 3700000.0, 3470000.0, 3160000.0, 630000.0, 8505000.0, 5530000.0, 3105000.0, 2695000.0, 1905000.0, 515000.0], std=[71005000.0, 68910000.0, 74840000.0, 69455000.0, 69490000.0, 26525000.0, 56010000.0, 56930000.0, 60815000.0, 62790000.0, 55040000.0, 29795000.0, 7070000.0, 8760000.0, 11460000.0, 14260000.0, 46270000.0, 31700000.0, 6035000.0, 7875000.0, 10225000.0, 15165000.0, 39425000.0, 30350000.0, 6765000.0, 8330000.0, 10465000.0, 16065000.0, 32770000.0, 30555000.0], max_pixel_value=1.0, normalization='standard'),\n",
       "  ToTensorV2(p=1.0, transpose_mask=False),\n",
       "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={'mask': 'mask'}, is_check_shapes=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the training dataloader\n",
    "\n",
    "train_loader = loader(train_path_imgs, \n",
    "                            train_path_masks, \n",
    "                            SIZE, \n",
    "                            LENGTH, \n",
    "                            BATCH_SIZE_FOR_TRAINING, \n",
    "                            transform=train_transform,\n",
    "                            for_stat=False)\n",
    "\n",
    "val_loader = loader(val_path_imgs, \n",
    "                            val_path_masks, \n",
    "                            SIZE, \n",
    "                            LENGTH, \n",
    "                            BATCH_SIZE_FOR_TRAINING, \n",
    "                            transform=val_transform,\n",
    "                            for_stat=False)\n",
    "\n",
    "train_batch = next(iter(train_loader))\n",
    "val_batch = next(iter(val_loader))\n",
    "\n",
    "print(\"Train Image Shape:\", train_batch['image'].shape)  # Expected: (batch_size, 6, H, W)\n",
    "print(\"Val Image Shape:\", val_batch['image'].shape)      # Expected: (batch_size, 6, H, W)\n",
    "\n",
    "# Checking normalization values\n",
    "print(\"Train Image Min/Max:\", train_batch['image'].min(), train_batch['image'].max())\n",
    "print(\"Val Image Min/Max:\", val_batch['image'].min(), val_batch['image'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
